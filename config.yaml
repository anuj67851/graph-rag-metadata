app_name: "My Graph RAG App"
api_v1_str: "/api/v1"

# --- LLM Models ---
llm_ingestion_model_name: "gpt-4o"
llm_query_response_model_name: "gpt-4o-mini"

# --- Embedding Model (Hugging Face) ---
# This repo will be used by Weaviate's text2vec-transformers module.
# Ensure the model selected here matches the one in the docker-compose service if pre-loading.
# Example: "sentence-transformers/all-mpnet-base-v2"
embedding_model_repo: "sentence-transformers/multi-qa-mpnet-base-cos-v1"
embedding_dimension: 768 # Must match the dimension of the chosen model

# --- File and Data Storage ---
schema_file_path: "schema.yaml"
prompts_file_path: "prompts.yaml"
# Directory for storing copies of uploaded original files
file_storage_path: "data/uploaded_files"
# Path for the SQLite database that tracks file metadata
sqlite_db_path: "data/file_metadata.db"
# Path for log files
log_file_path: "logs/graph_rag_app.log"
log_retention_days: 7

# --- Weaviate Configuration ---
# Name of the data collection (class) inside Weaviate
weaviate_class_name: "TextChunk"

# --- Retrieval Parameters ---
semantic_search_top_k: 3 # Number of text chunks to retrieve
entity_info_hop_depth: 1 # How many hops to explore around entities found in chunks

# --- Graph Explorer Defaults ---
default_full_graph_node_limit: 100
default_full_graph_edge_limit: 150