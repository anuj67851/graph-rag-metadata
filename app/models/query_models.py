from pydantic import BaseModel, Field
from typing import List, Optional
from app.models.common_models import Subgraph

class QueryRequest(BaseModel):
    """
    Represents the input for a user query to the backend.
    """
    query: str = Field(..., min_length=1, description="The natural language query from the user.")
    filter_filenames: Optional[List[str]] = Field(
        default=None,
        description="An optional list of filenames to restrict the query to."
    )
    # Optional: session_id for chat history, user_id for personalization, etc.
    # session_id: Optional[str] = None

class SourceChunk(BaseModel):
    """
    Represents a single source text chunk used as context for the RAG response.
    """
    source_document: str = Field(..., description="The filename of the source document for this chunk.")
    chunk_text: str = Field(..., description="The actual text content of the chunk.")
    score: float = Field(..., description="The similarity score from the vector search.")
    entity_ids: Optional[List[str]] = Field(default=None, description="List of entity IDs found in this chunk.")


class QueryResponse(BaseModel):
    """
    Represents the full response from the backend for a user query.
    This will be sent to the Streamlit UI.
    """
    llm_answer: str = Field(..., description="The final natural language answer generated by the LLM.")
    subgraph_context: Subgraph = Field(..., description="The subgraph data used as context for the LLM. For visualization.")
    source_chunks: List[SourceChunk] = Field(..., description="The list of source text chunks used as context for the LLM.")